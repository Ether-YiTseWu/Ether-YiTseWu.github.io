
<!doctype html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-KG2Z224XZ6"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-KG2Z224XZ6');
    </script>
    <meta name="google-site-verification" content="Ql3h9a7FWrkphYKX-yT592Jf6HSDyIj04aFeDpDdOKA" />
        
    <meta charset="utf-8">
    <title>Kaggle | Yi-Tse Wu 吳乙澤</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel='icon' href="/icons/favicon.ico">

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js" integrity="sha384-w76AqPfDkMBDXo30jS1Sgez6pr3x5MlQ1ZAGC+nuZB+EYdgRZgiwxhTBTkF7CXvN" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.0/font/bootstrap-icons.css">

    <link rel="stylesheet" href="/css/prism.css">

    <style>
        .p1
        {
            font-family: "Microsoft JhengHei";
            font-weight: bold;
        }
        .p2
        { 
            border-bottom:6px #48b9d9 solid; padding-bottom:5px;
        }
        .p3
        { 
            border-bottom:1px #9aa4a7 solid; padding-bottom:2px;
        }
        body 
        {
            background-color: #f4f8f8;
        }
    </style>
</head>

<body>
    <div class = "d-flex flex-row container-fluid mt-4">
        <a class = "text-decoration-none link-dark mb-1" href="https://ether-yitsewu.github.io/" style = "margin-right: auto;"> 
            <h3> &nbsp; &nbsp; Home </h3>
        </a>
        <a class = "text-decoration-none link-dark mt-2" href="/about.html">
                <h5> About &nbsp; &nbsp; &nbsp; &nbsp; </h5>
        </a>
        <a class = "text-decoration-none link-dark mt-2" href="/post/post.html">
            <h5> Post &nbsp; &nbsp; &nbsp; &nbsp; </h5>
        </a>
        <a class = "text-decoration-none link-dark mt-2" href="/contact.html">
            <h5> Contact &nbsp; &nbsp; &nbsp; &nbsp; </h5>
        </a>
    </div>

    <hr/>

    <div class = "row">
        <div class = "col-12 mt-4 text-center">
            <div style = "font-size: 2vw;">My solution to the competition, "Kaggle : Titanic"</div>
        </div>
    </div>

    <br>

    <div class = "row">
        <div class = "col-3"></div>
        <div class = "col-6 bg-white text-left">
            <br>
            <div style = "text-align:center;">
                <img src="/images/kaggle_02_show.jpg" alt="Kaggle show" style = "max-width:100%; height:auto;">
            </div>
            <br>
            <div style = "text-align:justify; font-size: 0.9vw;">
                <span style = "font-size: 1.5vw;">"K</span>aggle : Titanic<span style = "font-size: 1.5vw;">"</span> is an online competition for everbody getting started prediction problems.
                The goal is to classify the passengers are survived or not based on the features like the sex, ticket, and age.
                Because the competition is popular, there are many resources on Internet from enthusiastic netizens.
                Therefore, it's very suitable for the people who study data science and machine learning.
                In this article, I also share my solution to the Kaggle competition for increasing the positive self-learning community.
            </div>
            <br>
            <div style = "text-align:justify; font-size: 0.9vw;">
                <span style = "font-size: 1.5vw;">F</span>irstly, I would introduce my processing pipeline. 
                As the following figure shows, the pipeline is consist of six parts, "NaN", "Category", "Extract", "Normalize", "Model", and "Evaluate".
                In the "NaN" part, I drop out a feature named cabin whose NaN rate is too high.
                Then, I replace the NaN data with median.
                In the "Category" part, I use one-hot encoding to make category features computable.
                In the "Extract" part, I plot two scatter figures to observe the relationship between two different features.
                In the "Normalize" part, I nomalize the all data, and make the numerical interval of every data between 0 to 1 for decreasing the importance of "sex" feature. 
                In the "Model" part, I utilize NN and grid search methods to classify a person is survived or not.
                In the "Evaluate" part, I evaluate the goodness of model according to cross validation technique.
                The six parts indicate a rough image for you. 
                Therefore, in order to let you have a better sense of my soluition, I would introduce the three parts, "Extract", "Model", and "Evaluate" in detail.
                <br>
                <br>
                <div style = "text-align:center;">
                    <img src="/images/kaggle_02_pipeline.jpg" alt="Kaggle Pipeline" style = "max-width:100%; height:auto;">
                </div>
            </div>
            <br>
            <div style = "text-align:justify; font-size: 0.9vw;">
                <span style = "font-size: 1.5vw;">I</span>n the "Extract" part, I observe although the origin correlation coefficient of "SibSp" and "Survival" is lower than zero point one, we can use our data science brain to generate a better feature based on the "SibSp".
                Look at the following picture, we can observe thera is a specific relationship between "SibSp", "Parch", and "Survival". 
                Therefore, I acquire a new feature named "SibSpParch" whose correlation coefficient is higher than original value, zero point one.
                The extraction program of "SibSpParch" is simple as the following program shows.
                <br>
                <br>
                <div style = "text-align:center;">
                    <img src="/images/kaggle_02_SibSpParch.jpg" alt="Kaggle Pipeline" style = "max-width:100%; height:auto;">
                </div>
                <br>
                <div style = "font-size: 0.9vw;">
                    <pre class = "line-numbers language-python">
                        <code>
                            train_df_processing['SibSpParch'] = [int(i) for i in list((train_df_processing['SibSp'] >= 3) | (train_df_processing['Parch'] >= 4))]
                        </code>
                    </pre>
                </div>
            </div>
            <br>
            <div style = "text-align:justify; font-size: 0.9vw;">
                <span style = "font-size: 1.5vw;">I</span>n the "Model" and "Evaluate" part, as the following code, I build a NN model, use grid search to get a better patience, and evaluate the model by cross validation technique.
                <br>
                <br>
                <div style = "font-size: 0.9vw;">
                    <pre class = "line-numbers language-python">
                        <code>
                            for stop_patience in [100, 200, 300, 400, 500]:               
                                df = pd.read_csv("./train.csv")
                                df = df.drop('Cabin', axis = 1)
                                kf = KFold(n_splits = 10, shuffle = True, random_state = 42)
                                train_f1 = 0
                                train_auc = 0
                                valid_f1 = 0
                                valid_auc = 0
                                epo_len = 0
                                print("Patience :", stop_patience)
                                for ii, (train_index, valid_index) in enumerate(kf.split(df)):
                                    ### Set up
                                    df = pd.read_csv("./train.csv")
                                    df = df.drop('Cabin', axis = 1)
                                    ### Train
                                    train_df = df.loc[train_index]
                                    # Get the feature name of string and number type data
                                    string_feature = []
                                    number_feature = []
                                    for i in train_df.columns:
                                        if isinstance(train_df.iloc[0][i], str):
                                            string_feature.append(i)
                                        else:
                                            number_feature.append(i)
                                    train_df_one_hot = train_df.copy()
                                    # One-hot encoding
                                    labelencoder = LabelEncoder()
                                    for i in string_feature:
                                        train_df_one_hot[i] = labelencoder.fit_transform(train_df_one_hot[i])
                                    # String Feature. Replace NaN with median
                                    train_string_feature = train_df_one_hot[string_feature]
                                    train_string_feature = train_string_feature.fillna(train_string_feature.median())
                                    # Number Feature. Replace NaN with median
                                    train_number_feature = train_df_one_hot[number_feature]
                                    train_number_feature = train_number_feature.fillna(train_number_feature.median())
                                    # Concat
                                    train_df_processing = pd.concat([train_string_feature, train_number_feature], axis = 1)
                                    train_df_processing = train_df_processing.reset_index()

                                    ### valid
                                    validation_df = df.loc[valid_index]
                                    # Copy
                                    validation_df_ = validation_df.copy()
                                    # One-hot encoding
                                    labelencoder = LabelEncoder()
                                    validation_df_one_hot = validation_df_.copy()
                                    for i in string_feature:
                                        validation_df_one_hot[i] = labelencoder.fit_transform(validation_df_one_hot[i])
                                    # String Feature. Replace NaN with median
                                    validation_string_feature = validation_df_one_hot[string_feature]
                                    validation_string_feature = validation_string_feature.fillna(validation_string_feature.median())
                                    # Number Feature. Replace NaN with median
                                    validation_number_feature = validation_df_one_hot[number_feature]
                                    validation_number_feature = validation_number_feature.fillna(validation_number_feature.median())
                                    # Concat
                                    validation_df_processing = pd.concat([validation_string_feature, validation_number_feature], axis = 1)
                                    validation_df_processing = validation_df_processing.reset_index()
                                    
                                    ### Extract New Feature 
                                    train_df_processing['AgeSex'] = (train_df_processing['Sex']+2)*train_df_processing['Age']
                                    train_df_processing['SibSpParch'] = [int(i) for i in list(((train_df_processing['SibSp'] >= 3) & (train_df_processing['Parch'] >= 1)) | (train_df_processing['Parch'] >= 4))]

                                    validation_df_processing['AgeSex'] = (validation_df_processing['Sex']+2)*validation_df_processing['Age']
                                    validation_df_processing['SibSpParch'] = [int(i) for i in list(((validation_df_processing['SibSp'] >= 3) & (validation_df_processing['Parch'] >= 1)) | (validation_df_processing['Parch'] >= 4))]

                                    ### Normalization
                                    min_max_scaler_train = preprocessing.MinMaxScaler(feature_range=(0, 1)).fit(train_df_processing)

                                    col = train_df_processing.columns
                                    sur = train_df_processing.Survived
                                    train_df_processing = pd.DataFrame(min_max_scaler_train.fit_transform(train_df_processing))
                                    train_df_processing.columns = col
                                    train_df_processing.Survived = sur

                                    col = validation_df_processing.columns
                                    sur = validation_df_processing.Survived
                                    validation_df_processing = pd.DataFrame(min_max_scaler_train.fit_transform(validation_df_processing))
                                    validation_df_processing.columns = col
                                    validation_df_processing.Survived = sur

                                    ### Feature Select
                                    df = train_df_processing.corr()[['Survived']]
                                    df.columns = ["Correlation with the Survived"]
                                    feature_slect = df[(df['Correlation with the Survived'] >= 0.1) | (df['Correlation with the Survived'] <= -0.1)].T
                                    feature_slect = feature_slect.drop(['Survived', 'Ticket', 'Embarked'], axis = 1)

                                    ### Model
                                    ### Set up data
                                    x_train = train_df_processing[feature_slect.columns]
                                    y_train = train_df_processing['Survived']
                                    x_valid = validation_df_processing[feature_slect.columns]
                                    y_valid = validation_df_processing['Survived']

                                    ### Model Build
                                    model = Sequential()
                                    model.add(Dense(64, input_shape=(x_train.shape[1],), activation="gelu"))
                                    model.add(BatchNormalization())
                                    model.add(Dense(1, activation='sigmoid'))

                                    ### Parameters setting
                                    optimize = tf.keras.optimizers.Nadam()
                                    model.compile(loss = "binary_crossentropy", optimizer = optimize, metrics=["accuracy"])

                                    ### Training
                                    callback1 = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = stop_patience)
                                    callback2 = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', patience = 5, factor = 0.9, min_lr = 0.0000000001)
                                    model.fit(x_train, y_train, epochs = 4000, batch_size = 64, verbose = False, validation_data = (x_valid, y_valid), callbacks = [callback1])
                                    epo_len += len(model.history.history["loss"])

                                    ### Evaluate
                                    print("Data", ii, " loss :", model.history.history["loss"][-1], model.history.history["val_loss"][-1])
                                    # F1 Score
                                    predict = model.predict(x_valid)
                                    predict = [1 if i >= 0.5 else 0 for i in predict]
                                    valid_f1 += metrics.f1_score(y_valid, predict)
                                    predict = model.predict(x_train)
                                    predict = [1 if i >= 0.5 else 0 for i in predict]
                                    train_f1 += metrics.f1_score(y_train, predict)
                                    # AUC
                                    train_auc += metrics.roc_auc_score(y_train, model.predict(x_train))
                                    valid_auc += metrics.roc_auc_score(y_valid, model.predict(x_valid))

                                print("F1 SCore :", train_f1/10, valid_f1/10, ", AUC :",train_auc/10, valid_auc/10, ", Mean epochs length :", epo_len/10)
                                print()

                            print("End")
                        </code>
                    </pre>
                </div>
                <div style = "text-align:justify; font-size: 0.9vw;">
                    <br>
                    <span style = "font-size: 1.5vw;">F</span>inally, through the data pipeline and a multilayer perceptron model, I beats 50% people and acquire 0.78947 score as the following figure shows.
                    Hope this arcticle activate the people who study data science. 
                    Thank you for your time to read this arcticle.
                    <br>
                    <br>
                    <div style = "text-align:center;">
                        <img src="/images/kaggle_02_score.jpg" alt="Kaggle Score" style = "max-width:100%; height:auto;">
                    </div>
                </div>
            </div>
            <br>
        </div>
    </div>

    <br>
    <hr/>

    <div class = "d-flex justify-content-center align-items-center BottomRemain pb-3">
        <div class = "fw-lighter fs-6">
            <small>
                © 2023 
                <a href=https://ether-yitsewu.github.io/ class = "text-decoration-none link-dark p3"> Yi-Tse Wu 吳乙澤</a>
                 All Rights Reserved 
                &nbsp; &nbsp; &nbsp; &nbsp; 
                Powerd by 
                <a href=https://getbootstrap.com/docs/5.3/getting-started/download/ class = "text-decoration-none link-dark p3"> Bootstrap</a>
                ,
                <a href=https://github.com/michalsnik/aos class = "text-decoration-none link-dark p3"> AOS</a>
                ,
                <a href=https://www.hitwebcounter.com/ class = "text-decoration-none link-dark p3"> hitwebcounter</a>
                &
                <a href="https://www.google.com.tw/intl/zh-TW/forms/about/" class = "text-decoration-none link-dark p3"> Google Forms </a>
            </small>
        </div>
        &nbsp; &nbsp; &nbsp; &nbsp; 
        <a href="https://www.hitwebcounter.com" target="_blank">
        <img src="https://hitwebcounter.com/counter/counter.php?page=8308749&style=0008&nbdigits=6&type=page&initCount=0" title="Free Counter" Alt="web counter"/></a>                                                              
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
    <script src="/js/prism.js"></script>
    <script>
        AOS.init();
    </script>
</body>

</html>